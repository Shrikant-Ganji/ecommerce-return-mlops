# ğŸ›ï¸ Ecommerce Return Prediction â€” End-to-End MLOps Project

This repository demonstrates a complete **end-to-end MLOps pipeline** using:

* **Prefect 2.0** for orchestration and scheduled deployments
* **MLflow** for experiment tracking and model registry
* **Evidently AI** for monitoring data drift
* **Scikit-learn + Joblib** for modeling
* **GitHub Codespaces + Render** for development and deployment
* **GitHub Actions** for CI/CD automation
* **Terraform** for Infrastructure as Code (planned)

---

## ğŸ¯ Objective

Predict product returns in an e-commerce platform using historical order, customer, and product data. The project includes all key MLOps stages:

* Data preprocessing
* Model training and tracking
* Pipeline orchestration
* Model deployment (optional)
* Data drift monitoring
* Automation via CI/CD

---

## ğŸ§° Tech Stack Overview

| Component              | Tool / Platform            |
| ---------------------- | -------------------------- |
| Cloud/Dev Environment  | GitHub Codespaces + Render |
| Experiment Tracking    | MLflow                     |
| Workflow Orchestration | Prefect 2.0                |
| Monitoring             | Evidently AI               |
| CI/CD                  | GitHub Actions             |
| Infrastructure as Code | Terraform (Render or GCP)  |

---

## ğŸ“‚ Folder Structure & Module Overview

```bash
â”œâ”€â”€ data/                        # Raw, processed, and prediction data
â”œâ”€â”€ deployment/                 # FastAPI app and Render/K8s deployment config
â”œâ”€â”€ monitoring/                 # Drift detection scripts & HTML reports
â”œâ”€â”€ notebooks/                  # EDA, feature engineering, and training notebooks
â”œâ”€â”€ pipelines/                  # Prefect pipeline script
â”œâ”€â”€ prefect/                    # Prefect CLI configs, monitoring runner
â”œâ”€â”€ src/                        # Source code for training and prediction
â”œâ”€â”€ models/                     # Trained ML model (joblib format)
â”œâ”€â”€ mlruns/, mlflow.db          # MLflow tracking artifacts and metadata
â”œâ”€â”€ .github/workflows/ci.yml    # GitHub Actions pipeline for testing
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ prefect.yaml                # Prefect deployment CLI config
â”œâ”€â”€ Dockerfile, Makefile        # Docker & command automation
â”œâ”€â”€ run_deployment.py           # Script for triggering Prefect flow
â”œâ”€â”€ test_predict.py             # Test script for model inference
â”œâ”€â”€ terraform/                  # Infrastructure as Code (Render/GCP)
â””â”€â”€ README.md                   # Project documentation
```

---

## ğŸ“¦ Module Details

### ğŸ—ƒï¸ `data/`

* `raw/`: Contains original Olist e-commerce dataset CSVs.
* `processed/`: Preprocessed Parquet files: `train`, `test`, `X`, `y` splits.
* `predictions.csv`: Output file from inference pipeline.

### ğŸ§  `src/`

* `data_prep.py`: Loads raw data, handles missing values, encodes, and splits.
* `train.py`: Trains a Random Forest model, tracks with MLflow.
* `predict.py`: Generates predictions using the trained model.
* `utils.py`: Shared helper functions.

### ğŸ““ `notebooks/`

* `eda.ipynb`: Explore distributions, missing values, correlations.
* `feature_engineering.ipynb`: Encoding, scaling, and transformation logic.
* `model_training.ipynb`: Model experimentation + MLflow logging walkthrough.

### ğŸ§ª `models/`

* `return_model.joblib`: Final serialized version of the trained model.

### ğŸ“ `mlruns/`, `mlflow.db`

* MLflow tracking backend for:

  * Parameters
  * Metrics (Accuracy, F1-score)
  * Artifacts (model.pkl, conda.yaml, envs)

---

## âš™ï¸ Prefect 2.0 Orchestration

### ğŸ§µ `pipelines/prefect_flow.py`

Defines `@flow` called `full_pipeline()`:

* Loads â†’ preprocesses â†’ trains â†’ evaluates â†’ predicts â†’ monitors drift

### ğŸ§¾ `prefect.yaml`

* CLI-generated deployment config
* Allows you to run via:

```bash
prefect deploy -n "Ecommerce Return Pipeline"
```

### ğŸ§ª `prefect/run_monitoring_flow.py`

* Triggers monitoring task separately via CLI or script

### ğŸ§¾ `run_deployment.py`

* On-demand triggering of full Prefect pipeline

---

## ğŸ›°ï¸ Deployment Modules

### âš™ï¸ `deployment/app.py`

* Optional FastAPI app for serving predictions via `/predict`

### ğŸ§¾ `deployment/service.yaml`

* Kubernetes/Render-compatible YAML deployment descriptor

---

## ğŸ“Š Monitoring with Evidently

### ğŸ§­ `monitoring/evidently_monitor.py`

* Generates drift report by comparing reference vs current dataset
* Runs as Prefect task or cronjob

### ğŸ“Š `monitoring/evidently_report.html`

* Output HTML report from Evidently with visual metrics

---

## âœ… Tests

### ğŸ” `test_predict.py`

* Verifies that the saved model loads and makes predictions
* Ensures CI/CD test automation

---

## ğŸ Setup & Usage

### ğŸ”§ Environment Setup

```bash
conda create -n mlops311 python=3.11 -y
conda activate mlops311
pip install -r requirements.txt
```

### ğŸš¦ Start Prefect Server & Worker

```bash
prefect server start
prefect worker start -q default
```

### ğŸš€ Deploy the Pipeline

```bash
prefect deploy pipelines/prefect_flow.py:full_pipeline \
  -n "Ecommerce Return Pipeline" \
  -q "default" \
  -p "default-agent-pool"
```

### ğŸ” Trigger Manual Run

```bash
prefect deployment run 'ecommerce-return-mlops/Ecommerce Return Pipeline'
```

---

## ğŸ“ˆ Output & Artifacts

* ğŸ”¹ Drift Report: `monitoring/evidently_report.html`
* ğŸ”¹ Tracked Experiments: MLflow UI under `mlruns/`
* ğŸ”¹ Serialized Model: `models/return_model.joblib`
* ğŸ”¹ Scheduled Deployment: `prefect.yaml`

---

## ğŸ§  Best Practices Implemented

* âœ… GitHub Codespaces-friendly environment
* âœ… MLflow Tracking + Model Registry
* âœ… Prefect Flow Scheduling and Deployment
* âœ… Lightweight Containerized Deployment (optional)
* âœ… Drift Monitoring with Evidently
* âœ… CI/CD Pipeline with GitHub Actions
* âœ… Infrastructure-as-Code setup scaffold with Terraform

---

## ğŸ Future Enhancements

* ğŸ” Automated retraining and model versioning
* ğŸ§ª Unit tests for each module
* ğŸ“£ Slack/email alerts for drift detection
* â˜ï¸ Remote artifact logging (S3/GCS/Weights & Biases)
* ğŸ³ Publish Docker container on Render or GCP

---

## ğŸ‘¨â€ğŸ’» Author

**Shrikant Ganji**
ğŸš€ MLOps Zoomcamp | 2025 Edition
ğŸ”— [GitHub](https://github.com/Shrikant-Ganji)
